üîç CloudWatch is AWS's monitoring and observability service.

üìä It collects:
- Metrics (e.g., CPU, memory)
- Logs (e.g., app/server logs)
- Events (e.g., EC2 status changes)

üìà You can visualize this data using dashboards.


CloudWatch is like youri **bike or car dashboard**:
- Speed ‚Üí CPU usage
- Engine temp ‚Üí Disk I/O
- Fuel level ‚Üí Memory
- Red warning light ‚Üí Alarm

It tells you when something goes wrong and helps you fix it.


Monitor health and performance of AWS resources  
üì¨ Get alerts via email/SMS when thresholds are crossed  
üîÅ Automatically trigger actions (e.g., restart EC2)  
üìâ Centralized log monitoring  
üìä Create custom dashboards


Core Components:
- Metrics: e.g., CPUUtilization
- Logs: App/system logs
- Alarms: Notify or act when thresholds are breached
- Dashboards: Graphs and charts
- Events: Automate reactions to changes


CloudTrail records every **API call** made in AWS.

It tracks:
- Who performed the action
- What action was taken
- When and from where

Used for **auditing, security, and compliance.**

Think of CloudTrail as **CCTV in a bank**:
- Records who entered (User)
- What they did (Create/Delete)
- When and how (Time, IP, Region)

It helps you investigate incidents and track history.

Know who did what in your AWS account  
üßæ Comply with audit and security policies  
üö® Detect unauthorized access or changes  
üï∞Ô∏è See all actions in the last 90 days (default)


üß± Core Concepts:
- Events: Each API call (e.g., RunInstances)
- Event History: View 90 days by default
- Trails: Save logs in S3 for long-term use
- Insights: Detect unusual activity (e.g., login spike)

üîÅ Works across regions and services


Use Case: Bucket was deleted accidentally

üë£ Steps:
1. Go to CloudTrail ‚Üí Event History
2. Search: Event Name = DeleteBucket
3. Review details:
   - Username
   - Time
   - Region
   - IP Address

üîí Now you know exactly who did it and w


sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform


name: Simple S3 Create

on: [workflow_dispatch]

jobs:
  create-s3:
    runs-on: ubuntu-latest
    steps:
      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - run: aws s3 mb s3://my-simple-gh-bucket-${{ github.run_id }}r




terraform {
  backend "s3" {
    bucket         = "your-terraform-state-bucket"
    key            = "alb-path-routing/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"
    encrypt        = true
  }
}

provider "aws" {
  region = "us-east-1"
}




variable "vpc_cidr" {
  default = "10.0.0.0/16"
}

variable "public_subnets" {
  default = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
}

variable "availability_zones" {
  default = ["us-east-1a", "us-east-1b", "us-east-1c"]
}


#!/bin/bash
yum install -y nginx
echo "<h1>Homepage</h1>" > /usr/share/nginx/html/index.html
systemctl start nginx
systemctl enable nginx

#!/bin/bash
yum install -y nginx
mkdir -p /usr/share/nginx/html/images
echo "<h1>Images Path</h1>" > /usr/share/nginx/html/images/index.html
systemctl start nginx
systemctl enable nginx

#!/bin/bash
yum install -y nginx
mkdir -p /usr/share/nginx/html/register
echo "<h1>Register Page</h1>" > /usr/share/nginx/html/register/index.html
systemctl start nginx
systemctl enable nginx




provider "aws" {
  region = "us-east-1"
}

#------------------------
# 1. VPC and Networking
#------------------------

resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_internet_gateway" "igw" {
  vpc_id = aws_vpc.main.id
}

resource "aws_subnet" "subnet_a" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.1.0/24"
  availability_zone       = "us-east-1a"
  map_public_ip_on_launch = true
}

resource "aws_subnet" "subnet_b" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.2.0/24"
  availability_zone       = "us-east-1b"
  map_public_ip_on_launch = true
}

resource "aws_subnet" "subnet_c" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.3.0/24"
  availability_zone       = "us-east-1c"
  map_public_ip_on_launch = true
}

resource "aws_route_table" "rt" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.igw.id
  }
}

resource "aws_route_table_association" "a" {
  subnet_id      = aws_subnet.subnet_a.id
  route_table_id = aws_route_table.rt.id
}

resource "aws_route_table_association" "b" {
  subnet_id      = aws_subnet.subnet_b.id
  route_table_id = aws_route_table.rt.id
}

resource "aws_route_table_association" "c" {
  subnet_id      = aws_subnet.subnet_c.id
  route_table_id = aws_route_table.rt.id
}

#------------------------
# 2. Security Group
#------------------------

resource "aws_security_group" "web_sg" {
  name   = "web-sg"
  vpc_id = aws_vpc.main.id

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

#------------------------
# 3. Launch EC2s with Nginx
#------------------------

resource "aws_instance" "instance_a" {
  ami           = "ami-0c02fb55956c7d316" # Amazon Linux 2
  instance_type = "t2.micro"
  subnet_id     = aws_subnet.subnet_a.id
  vpc_security_group_ids = [aws_security_group.web_sg.id]

  user_data = <<-EOF
              #!/bin/bash
              yum install -y nginx
              echo "<h1>Home page!</h1>" > /usr/share/nginx/html/index.html
              systemctl start nginx
              systemctl enable nginx
            EOF

  tags = { Name = "InstanceA" }
}

resource "aws_instance" "instance_b" {
  ami           = "ami-0c02fb55956c7d316"
  instance_type = "t2.micro"
  subnet_id     = aws_subnet.subnet_b.id
  vpc_security_group_ids = [aws_security_group.web_sg.id]

  user_data = <<-EOF
              #!/bin/bash
              yum install -y nginx
              mkdir -p /usr/share/nginx/html/images
              echo "<h1>Images!</h1>" > /usr/share/nginx/html/images/index.html
              systemctl start nginx
              systemctl enable nginx
            EOF

  tags = { Name = "InstanceB" }
}

resource "aws_instance" "instance_c" {
  ami           = "ami-0c02fb55956c7d316"
  instance_type = "t2.micro"
  subnet_id     = aws_subnet.subnet_c.id
  vpc_security_group_ids = [aws_security_group.web_sg.id]

  user_data = <<-EOF
              #!/bin/bash
              yum install -y nginx
              mkdir -p /usr/share/nginx/html/register
              echo "<h1>Register!</h1>" > /usr/share/nginx/html/register/index.html
              systemctl start nginx
              systemctl enable nginx
            EOF

  tags = { Name = "InstanceC" }
}

#------------------------
# 4. Application Load Balancer
#------------------------

resource "aws_lb" "alb" {
  name               = "app-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.web_sg.id]
  subnets            = [aws_subnet.subnet_a.id, aws_subnet.subnet_b.id, aws_subnet.subnet_c.id]
}

resource "aws_lb_target_group" "tg_home" {
  name     = "tg-home"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
}

resource "aws_lb_target_group" "tg_images" {
  name     = "tg-images"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
}

resource "aws_lb_target_group" "tg_register" {
  name     = "tg-register"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
}

resource "aws_lb_target_group_attachment" "attach_home" {
  target_group_arn = aws_lb_target_group.tg_home.arn
  target_id        = aws_instance.instance_a.id
  port             = 80
}

resource "aws_lb_target_group_attachment" "attach_images" {
  target_group_arn = aws_lb_target_group.tg_images.arn
  target_id        = aws_instance.instance_b.id
  port             = 80
}

resource "aws_lb_target_group_attachment" "attach_register" {
  target_group_arn = aws_lb_target_group.tg_register.arn
  target_id        = aws_instance.instance_c.id
  port             = 80
}

resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.alb.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.tg_home.arn
  }
}

resource "aws_lb_listener_rule" "images" {
  listener_arn = aws_lb_listener.http.arn
  priority     = 100

  action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.tg_images.arn
  }

  condition {
    path_pattern {
      values = ["/images*"]
    }
  }
}

resource "aws_lb_listener_rule" "register" {
  listener_arn = aws_lb_listener.http.arn
  priority     = 200

  action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.tg_register.arn
  }

  condition {
    path_pattern {
      values = ["/register*"]
    }
  }
}


name: Terraform ALB Path Routing

on:
  push:
    branches:
      - main
  pull_request:

permissions:
  id-token: write  # Required for OIDC
  contents: read   # Required for actions/checkout

jobs:
  deploy:
    name: Terraform Deploy
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Configure AWS credentials via OIDC
      uses: aws-actions/configure-aws-credentials@v2
      with:
        role-to-assume: arn:aws:iam::<ACCOUNT_ID>:role/<GITHUB_OIDC_ROLE_NAME>
        aws-region: us-east-1

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.7  # or your preferred version

    - name: Terraform Init
      run: terraform init

    - name: Terraform Format
      run: terraform fmt -check

    - name: Terraform Validate
      run: terraform validate

    - name: Terraform Plan
      run: terraform plan

    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      run: terraform apply -auto-approve


