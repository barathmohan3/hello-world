🔍 CloudWatch is AWS's monitoring and observability service.

📊 It collects:
- Metrics (e.g., CPU, memory)
- Logs (e.g., app/server logs)
- Events (e.g., EC2 status changes)

📈 You can visualize this data using dashboards.


CloudWatch is like youri **bike or car dashboard**:
- Speed → CPU usage
- Engine temp → Disk I/O
- Fuel level → Memory
- Red warning light → Alarm

It tells you when something goes wrong and helps you fix it.


Monitor health and performance of AWS resources  
📬 Get alerts via email/SMS when thresholds are crossed  
🔁 Automatically trigger actions (e.g., restart EC2)  
📉 Centralized log monitoring  
📊 Create custom dashboards


Core Components:
- Metrics: e.g., CPUUtilization
- Logs: App/system logs
- Alarms: Notify or act when thresholds are breached
- Dashboards: Graphs and charts
- Events: Automate reactions to changes


CloudTrail records every **API call** made in AWS.

It tracks:
- Who performed the action
- What action was taken
- When and from where

Used for **auditing, security, and compliance.**

Think of CloudTrail as **CCTV in a bank**:
- Records who entered (User)
- What they did (Create/Delete)
- When and how (Time, IP, Region)

It helps you investigate incidents and track history.

Know who did what in your AWS account  
🧾 Comply with audit and security policies  
🚨 Detect unauthorized access or changes  
🕰️ See all actions in the last 90 days (default)


🧱 Core Concepts:
- Events: Each API call (e.g., RunInstances)
- Event History: View 90 days by default
- Trails: Save logs in S3 for long-term use
- Insights: Detect unusual activity (e.g., login spike)

🔁 Works across regions and services


Use Case: Bucket was deleted accidentally

👣 Steps:
1. Go to CloudTrail → Event History
2. Search: Event Name = DeleteBucket
3. Review details:
   - Username
   - Time
   - Region
   - IP Address

🔒 Now you know exactly who did it and w


sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform


name: Simple S3 Create

on: [workflow_dispatch]

jobs:
  create-s3:
    runs-on: ubuntu-latest
    steps:
      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - run: aws s3 mb s3://my-simple-gh-bucket-${{ github.run_id }}r




terraform {
  backend "s3" {
    bucket         = "your-terraform-state-bucket"
    key            = "alb-path-routing/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"
    encrypt        = true
  }
}

provider "aws" {
  region = "us-east-1"
}




variable "vpc_cidr" {
  default = "10.0.0.0/16"
}

variable "public_subnets" {
  default = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
}

variable "availability_zones" {
  default = ["us-east-1a", "us-east-1b", "us-east-1c"]
}



